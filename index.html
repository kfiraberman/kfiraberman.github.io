
<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="utf-8">
	<title>Kfir Aberman</title>
	<meta name="description" content="" />
  	<meta name="keywords" content="" />
	<meta name="robots" content="" />

	<link href='https://fonts.googleapis.com/css?family=Maven+Pro:700,900|Open+Sans:300italic,400italic,600italic,400,300,600' rel='stylesheet' type='text/css'>

	<link href="css/reset.css" rel="stylesheet" type="text/css" />
	<link href="css/960.css" rel="stylesheet" type="text/css" />
	<link href="css/styles.css" rel="stylesheet" type="text/css" />
	<link href="fancybox/jquery.fancybox-1.3.4.css" rel="stylesheet" type="text/css" />

	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
	<script type="text/javascript" src="js/smooth-scroll.js"></script>
	<script type="text/javascript" src="js/jquery.sticky.js"></script>
	<script type="text/javascript" src="fancybox/jquery.fancybox-1.3.4.pack.js"></script>
	<script type="text/javascript" src="js/jquery.easing-1.3.pack.js"></script>
	<script type="text/javascript" src="fancybox/jquery.mousewheel-3.0.4.pack.js"></script>
	<script type="text/javascript" src="cform.js"></script>

<script type="text/javascript"> // sticky nav bar
  $(document).ready(function(){
    $("nav").sticky({topSpacing:0});
  });
</script>

<script type="text/javascript"> // fancybox
$(document).ready(function() {

	/* This is basic - uses default settings */

	$("a.single_image").fancybox();

	/* Using custom settings */

	$("a#inline").fancybox({
		'hideOnContentClick': true
	});

	/* Apply fancybox to multiple items */

	$("a.group").fancybox({
		'transitionIn'	:	'elastic',
		'transitionOut'	:	'elastic',
		'speedIn'		:	600,
		'speedOut'		:	200,
		'overlayShow'	:	false
	});

});
</script>

</head>

<div class="topbar"></div> <!-- top bar -->



<nav>
	<ul>
   	    <li><a href="#about">About</a></li>
		<li><a href="#publications">Publications</a></li>
		<li></li>
	</ul>
</nav> <!-- end nav -->

<div id="about">
	<div class="container_16">

    <div class="grid_6">
      <div class="about_copy">
            <h1>Kfir Aberman</h1>
            <br><br>
            <p>Research Scientist</p>
            <p>Google Research</p>
            <p><img src="img/icn_mail_white.png" alt="" />  kfiraberman @ gmail . com</p>
          <!-- <p><img src="img/icn_address_white.png" alt="" /> Building A, Beijing Film Academy, Haidian, Beijing<br /> -->
      </div> <!-- end .about_copy -->
    </div> <!-- end .grid_6 -->


      <div class="grid_5">
		      <div class="about_pic"></div>
	   </div> <!-- end .grid_5 -->



	</div> <!-- end .container_16 -->
</div> <!-- end #about -->


<div id="about">
	<div class="container_16">

	<div class="grid_6">
			<div class="about_copy2">
            <h2>Short Bio  </h2>
            <br>
            <p class="bio">I'm a research scientist at Google Research. I received my Ph.D from Tel-Aviv University where I was advised by Daniel Cohen-Or. Earlier, I obtained my B.Sc (summa cum laude) and M.Sc (cum laude) from the Department of Electrical Engineering at the Technion. I conduct research and develop tools for various graphics applications using the power of deep neural networks. In particular, I work on analysis and synthesis of human motion in real videos as well as 3D character animation.</p>
            <p class="bio">I grew up in a small town in Israel called Zefat, lived in Tel-Aviv as an adult, spent 3 wonderful years in China as a researcher, and currently Iâ€™m based in San-Francisco.</p>
            <!-- <p class="bio">In addition, I review papers of top tier venues in graphics, and have extensive experience in code writing and algorithm development on various platforms.</p> -->
      <!-- <p>I am currently a researcher in <A href="https://www.microsoft.com/en-us/research/group/visual-computing/">Visual Computing Group</A> at Microsoft Research Asia (MSRA). Before I joined MSRA in Dec. 2015, I received my dual Ph.D. degrees from Zhejiang University and Hong Kong University of Science and Technology, under the supervision of  Prof. <A href="http://www.cad.zju.edu.cn/home/jhyu/English.htm">Jinhui Yu</A> and Prof. <A href="http://www.cse.ust.hk/~psander/">Pedro V. Sander</A>.</p> -->
           </div> <!-- end .about_copy -->
	</div> <!-- end .grid_6 -->

	<div class="grid_5">
		<div class="skills">
			<h2>Research Interests</h2>
			<ul>
        <li><div class="skill2"><p><strong>Deep Learning</strong></p></div></li>
				<li><div class="skill2"><p><strong>Computer Graphics</strong></p></div></li>
				<li><div class="skill2"><p><strong>Character Animation</strong></p></div></li>


			</ul>
		</div> <!-- end .skills -->
	</div>
	 <!-- end .grid_5 -->

	</div> <!-- end .container_16 -->
</div> <!-- end #about -->
<div class="about_bg_bottom"></div>

<div id="publications">
	<div class="container_16">

		<div class="subheader">
			<div class="subheader_line"></div><h3>publications</h3><div class="subheader_line"></div>
		</div>

		<div class="gallery">

        <div class="titleheader">

        <br></br>

      <div class="container_16">
           <div class="grid_5">
        <a href="img/motionet_1.png" class="single_image"><div class="screenshot10 ss"></div></a>
         </div>

         <div class="tt">
       <p>Mingyi Shi, <strong>Kfir Aberman</strong>, Andreas Aristidou, Taku Komura, Dani Lischinski, Daniel Cohen-Or, Baoquan Chen. <strong>MotioNet: 3D Human Motion Reconstruction from Video with Skeleton Consistency</strong>,</p>
       <p><em>Transactions on Graphics (ToG) 2020</em>. </p>
         <p class="intro_line">[<a href="https://rubbly.cn/publications/motioNet/">Webpage</a>][<a href="https://arxiv.org/pdf/2006.12075v1.pdf">Paper</a>][<a href="https://www.youtube.com/watch?v=8YubchlzvFA">Video</a>][<a href="https://github.com/Shimingyi/MotioNet">Code</a>]</p>
       </p>

        </div>
  </div>

      <br></br>

      <div class="container_16">
           <div class="grid_5">
        <a href="img/skeleton_aware.jpg" class="single_image"><div class="screenshot9 ss"></div></a>
         </div>

          <div class="tt">
        <p><strong>Kfir Aberman</strong>*, Peizhuo Li*, Dani Lischinski, Olga Sorkine-Hornung, Daniel Cohen-Or, Baoquan Chen. <strong>Skeleton-Aware Networks for Deep Motion Retargeting</strong>,</p>
        <p><em>SIGGRAPH 2020</em>. </p>
          <p class="intro_line">[<a href="https://deepmotionediting.github.io/retargeting">Webpage</a>][<a href="https://arxiv.org/abs/2005.05732">Paper</a>][<a href="https://www.youtube.com/watch?v=ym8Tnmiz5N8">Video</a>][<a href="https://github.com/DeepMotionEditing/deep-motion-editing">Code</a>]</p>
        </p>

        </div>
  </div>

        <br></br>

    		  <div class="container_16">
               <div class="grid_5">
    				<a href="img/MST.gif" class="single_image"><div class="screenshot8 ss"></div></a>
             </div>

             <div class="tt">
           <p><strong>Kfir Aberman</strong>*, Yijia Weng*, Dani Lischinski, Daniel Cohen-Or, Baoquan Chen. <strong>Unpaired Motion Style Transfer from Video to Animation</strong>,</p>
           <p><em>SIGGRAPH 2020</em>. </p>
             <p class="intro_line">[<a href="https://deepmotionediting.github.io/style_transfer">Webpage</a>][<a href="https://arxiv.org/abs/2005.05751">Paper</a>][<a href="https://www.youtube.com/watch?v=m04zuBSdGrc">Video</a>][<a href="https://github.com/DeepMotionEditing/deep-motion-editing">Code</a>]</p>
           </p>

            </div>
    	</div>

        <br></br>

    		  <div class="container_16">
               <div class="grid_5">
    				<a href="img/LCAM_1.gif" class="single_image"><div class="screenshot7 ss"></div></a>
             </div>

              <div class="tt">
    				<p><strong>Kfir Aberman</strong>, Rundi Wu, Dani Lischinski, Chen Baoquan, Daniel Cohen-Or. <strong>Learning Character-Agnostic Motion for Motion Retargeting in 2D</strong>,</p>
            <p><em>SIGGRAPH 2019</em>. </p>
    					<p class="intro_line">[<a href="http://motionretargeting2d.github.io">Webpage</a>][<a href="https://arxiv.org/abs/1905.01680">Paper</a>][<a href="https://youtu.be/fR4h4OjZSdU">Video</a>][<a href="https://github.com/ChrisWu1997/2D-Motion-Retargeting">Code</a>]</p>
    				</p>

            </div>
    	</div>

      <br></br>

  		  <div class="container_16">
             <div class="grid_5">
  				<a href="img/performance_cloning_EG.png" class="single_image"><div class="screenshot6 ss"></div></a>
           </div>

            <div class="tt">
  				<p><strong>Kfir Aberman</strong>, Mingyi Shi, Jing Liao, Dani Lischinski, Chen Baoquan, Daniel Cohen-Or. <strong>Deep Video-Based Performance Cloning</strong>,</p>
          <p><em>Eurographics 2019</em>. </p>
  					<p class="intro_line">[<a href="https://arxiv.org/abs/1808.06847">Paper</a>][<a href="https://www.youtube.com/watch?v=JpwsEeqNhhA">Video</a>]</p>
  				</p>

          </div>
  	</div>

      <br></br>


		  <div class="container_16">
           <div class="grid_5">
				<a href="img/NBBs.png" class="single_image"><div class="screenshot5 ss"></div></a>
         </div>

          <div class="tt">
				<p><strong>Kfir Aberman</strong>, Jing Liao, Mingyi Shi, Dani Lischinski, Chen Baoquan, Daniel Cohen-Or. <strong>Neural Best-Buddies: Sparse Cross-Domain Correspondence</strong>,</p>
         <p><em>SIGGRAPH 2018.</em></p>
					<p class="intro_line">[<a href="https://kfiraberman.github.io/neural_best_buddies/">Webpage</a>][<a href="https://arxiv.org/abs/1805.04140">Paper</a>][<a href="https://www.youtube.com/watch?v=tYqkMGaGmkk&t=83s">Video</a>][<a href="https://github.com/kfiraberman/neural_best_buddies">Code</a>]</p>
				</p>

        </div>
	</div>

    <br></br>


     <div class="titleheader">

        <div class="container_16">
        <div class="grid_5">
				<a href="img/dipTransform.jpg" class="single_image"><div class="screenshot4 ss"></div></a>
        </div>

         <div class="tt">
           <p><strong>Kfir Aberman</strong>, Oren Katzir, Qiang Zhou, Zegang Luo, Andrei Sharf, Chen Greif, Chen Baoquan, Daniel Cohen-Or. <strong>Dip Transform for 3D Shape Reconstruction</strong>,</p>
            <p><em>SIGGRAPH 2017.</em></p>
   					<p class="intro_line">[<a href="https://www.cs.tau.ac.il/~dcor/articles/2017/Dip.Transform.pdf">Paper</a>]</p>
   				</p>

        </div>
         </div>
         <br></br>



	<div class="container_16">
        <div class="grid_5">
				<a href="img/journalSAR.png" class="single_image"><div class="screenshot3 ss"></div></a>
         </div>

         <div class="tt">
				<p><strong>Kfir Aberman</strong>, Yonina C. Eldar, <strong>Sub-Nyquist SAR via Fourier Domain Range-Doppler Processing</strong>, <em>IEEE Transactions on Geoscience and Remote Sensing</em>, Issue 11, 6228 - 6244, Aug 2017</p> <p>[<a href="https://arxiv.org/pdf/1608.04138">Paper</a>]</p>

        </div>
         </div>
         <br></br>
   <div class="container_16">
     <div class="grid_5">
 				<a href="img/adaptive.png" class="single_image"><div class="screenshot2 ss"></div></a>
          </div>

          <div class="tt">
 				<p><strong>Kfir Aberman</strong>, Shay Aviv, Yonina C. Eldar, <strong>Adaptive frequency allocation in radar imaging: Towards cognitive SAR</strong>, <em>IEEE Radar Conference (RadarConf)</em>, May 2017</p> <p>[<a href="http://ieeexplore.ieee.org/abstract/document/7944415/">Paper</a>]</p>
      </div>
  </div>
          <br></br>
  <div class="container_16">
        <div class="grid_5">
				<a href="img/board.png" class="single_image"><div class="screenshot1 ss"></div></a>
         </div>

         <div class="tt">
				<p><strong>Kfir Aberman</strong>, Yonina C. Eldar, <strong>Range-Doppler processing via Fourier coefficients: The path to a sub-Nyquist SAR</strong>, <em>IEEE Radar Conference (RadarConf)</em>, May 2016</p> <p>[<a href="http://ieeexplore.ieee.org/abstract/document/7485295/">Paper</a>]</p>
	     </div>
	</div>
  <br></br>
<div class="container_16">
<div class="grid_5">
<a href="img/realData.png" class="single_image"><div class="screenshot0 ss"></div></a>
 </div>

 <div class="tt">
<p><strong>Kfir Aberman</strong>, Yonina C. Eldar, <strong>Compressive Sensing of SAR Signals via Fourier Coefficients</strong>, <em>EUSAR (European Conference on Synthetic Aperture Radar)</em>, June 2016</p> <p>[<a href="http://ieeexplore.ieee.org/abstract/document/7559457/">Paper</a>]</p>
</div>
</div><!-- end .gallery -->
</div> <!-- end .container_16 -->


</div> <!-- end #publications -->

<div class="publications_bg_bottom"></div><!-- end #work -->

<!-- end #contact -->

<footer>
  <p>&nbsp;</p>
</footer>
<!-- <a href="http://xyz.freelogs.com/stats/k/kfir77777/" target="_top"><img width="30" border="0" alt="hit counter javascript" src="http://xyz.freelogs.com/counter/index.php?u=kfir77777&s=binky" ALIGN="middle" HSPACE="4" VSPACE="2"></a><script src=http://xyz.freelogs.com/counter/script.php?u=kfir77777></script>
<br><a style="font-size:12" href="http://www.freelogs.com/create.php" target="_top"></a> -->
<div class="about_bg_bottom"></div>
